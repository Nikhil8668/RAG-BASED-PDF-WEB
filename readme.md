I built a web application that lets users upload large PDF documents (even 500+ pages) and then ask conversational questions about their content. The system uses a Retrieval-Augmented Generation (RAG) pipeline with OpenAIâ€™s LLMs, embeddings, and FAISS to provide accurate, citation-based answers.

As I dont have a openai api  access so I have just developed the opplication as it will not generate the answers and cant able to converts the data into vectors due to insufficent quota in openapi
As you can use your own api tokken to generate the answer or you can use open source llm models  

Thanks

Nikhil Sangle
